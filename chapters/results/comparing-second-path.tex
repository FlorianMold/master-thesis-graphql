\section{Comparing the results of the second user journey}\label{section:results:comparison-second-journey}

This section shows another but more concise comparison of the results between the three approaches explained in \ref{section:results:performance-measurement}. The journey of the client through the application is shown in figure \ref{fig:results:evaluation-second-path}. The client has to perform 17 steps throughout the application, which involves running every available GraphQL query. In contrast to the first journey from \ref{section:results:comparison-first-journey}, the client uses an authenticated user to perform the test. The GraphQL \ac{API} request to retrieve the authenticated user has to be done by every micro-frontend individually, with the default approach with a separate cache.

\ifshowImages
\begin{figure}[H]
\centering
\includegraphics[width=1\linewidth]{images/results/evaluation-second-path.png}
\caption{The second user journey through the application to measure the performance of the micro-frontend architecture.}\label{fig:results:evaluation-second-path}
\end{figure}
\fi

\noindent The next sections compare the three different approaches in terms of request sizes and response sizes, the number of requests, and the total records fetched just like in the previous section \ref{section:results:comparison-first-journey}.

\subsection{Comparing the first- and second-approach}\label{subsection:results:comparison-second-path-first-second-approach}

When comparing the first- with the second approach there is a difference of 25 network requests made to the GraphQL \ac{API} and the size of the requests and responses, as seen in table \ref{table:results:size-comparison-second-path-cache-no-reduction-cache-reduction}. There are no reduced queries for this comparison, the 25 extra requests account for the difference in size. 22\% of the total response size can be saved by using a shared cache layer. Another interesting observation is that the shared cache approach retrieves 30401 fewer records than the naive approach, which is about 37\% of the total records returned.

\ifshowTables
\begin{table}[H]
  \begin{tabular}{|l|l|l|l|l|}
  \hline
  & \textbf{Request Size (B)} & \textbf{Response Size (B)} & \textbf{Requests} & \textbf{Records} \\
  \hline
  \textbf{No Reduction, Separate Cache} & 22955 & 10713304 & 62 & 81325 \\
  \hline
  \textbf{No Reduction, Shared Cache} & 16884 & 8364416 & 37 & 50924 \\
  \hline
  \hline
  \textbf{Diff} & \textbf{6071} & \textbf{2348888} & \textbf{25} & \textbf{30401} \\
  \hline
  \textbf{Reduction (\%)} & \textbf{26\%} & \textbf{22\%} & \textbf{40\%} & \textbf{37\%} \\
  \hline
  \end{tabular}
  \caption{Second Journey: Comparing the requests and responses of the second- and third-approach.}\label{table:results:size-comparison-second-path-cache-no-reduction-cache-reduction}
\end{table}
\fi

\subsection{Comparing the first- and third-approach}\label{subsection:results:comparison-second-path-second-third-approach}

Like the previous comparison, there are again 25 requests less made to the GraphQL \ac{API}. The size of the responses and the requests have about the same difference like before. The results are shown in table \ref{table:results:size-comparison-second-path-no-cache-no-reduction-cache-reduction}. However, due to the reduction in queries, the difference in the size of the queries and responses is a bit greater than in section \ref{table:results:size-comparison-second-path-cache-no-reduction-cache-reduction}. A shared caching layer and query reduction can save about 22\% of response size. As before, 37\% fewer records need to be fetched from the backend.

\ifshowTables
\begin{table}[H]
  \begin{tabular}{|l|l|l|l|l|}
  \hline
  & \textbf{Request Size (B)} & \textbf{Response Size (B)} & \textbf{Requests} & \textbf{Records} \\
  \hline
  \textbf{No Reduction, Separate Cache} & 22955 & 10713304 & 62 & 81325 \\
  \hline
  \textbf{Reduction, Shared Cache} & 14718 & 8361306 & 37 & 50924 \\
  \hline
  \hline
  \textbf{Diff} & \textbf{8237} & \textbf{2351998} & \textbf{25} & \textbf{30401} \\
  \hline
  \textbf{Reduction (\%)} & \textbf{35\%} & \textbf{22\%} & \textbf{40\%} & \textbf{37\%} \\
  \hline
  \end{tabular}
  \caption{Second Journey: Comparing the requests and responses of the first- and third-approach.}\label{table:results:size-comparison-second-path-no-cache-no-reduction-cache-reduction}
\end{table}
\fi

\subsection{Comparing the second- and third-approach}\label{subsection:results:comparison-second-path-first-third-approach}

Between the first- and the second approach, there is almost no difference in terms of request- and response size. The results are displayed table \ref{table:results:size-comparison-first-path-no-cache-no-reduction-cache-reduction}. Both approaches have the same number of queries sent to the GraphQL \ac{API} since the cache is shared by all micro-frontends. The difference in request and response size comes only from using the query reduction mechanism. The difference in request size is 11\%, but they account for just 1.64 KB, which is not significant. The difference between the response sizes (62.45 KB) is almost zero like in the first journey.

\ifshowTables
\begin{table}[H]
\begin{tabular}{|l|l|l|l|l|}
  \hline
  & \textbf{Request Size (B)} & \textbf{Response Size (B)} & \textbf{Requests} & \textbf{Records} \\
  \hline
  \textbf{No Reduction, Shared Cache} & 16884 & 8364416 & 37 & 50924 \\
  \hline
  \textbf{Reduction, Shared Cache} & 14718 & 8361306 & 37 & 50924 \\
  \hline
  \hline
  \textbf{Diff} & \textbf{2166} & \textbf{3110} & \textbf{0} & \textbf{0} \\
  \hline
  \textbf{Reduction (\%)} & \textbf{13\%} & \textbf{0\%} & \textbf{-} & \textbf{-} \\
  \hline
  \end{tabular}
  \caption{Second Journey: Comparing the requests and responses of the first- and second-approach.}\label{table:results:size-comparison-second-path-no-cache-no-reduction-cache-no-reduction}
\end{table}
\fi