\chapter{Introduction}\label{chapter:introduction}

The company AGnet\footnote{\url{https://www.agnet.at/}} has an outdated monolithic \ac{ERP} system to manage its customers, sales, and so on. The technology stack is deprecated and must be upgraded. A migration to newer technology is necessary. The new architecture should consist of micro-frontends on the frontend and microservices on the backend. Some microservices are already in development, and a prototypical micro-frontend architecture should be developed within the scope of this master thesis, which should lay the groundwork for the architecture. Micro-frontends face different problems than traditional frontend applications, and the prototype developed should address the issues that a distributed architecture brings. The prototype should be able to completely replace the old monolithic application in the future, and the prototype should provide the same functionality as the old application.

\bigskip

\noindent The master thesis is structured in a theoretical part, and a practical part follows it. The final chapters present and discuss the results of the work. This Chapter describes the motivation and the hypothesis for this thesis. Chapter \ref{chapter:background} describes the principles of software monoliths, \ac{API} abstractions, micro-frontends, and GraphQL. Chapter \ref{chapter:applied-methods} covers the methods applied to develop the micro-frontend prototype and deal with over-fetching and over-requesting. It describes the most significant problems and hurdles during the development and their solutions. The results can be found in Chapter \ref{chapter:results}, and the discussion revolving around the results is in Chapter \ref{chapter:discussion}. Chapter \ref{chapter:conclusion} concludes the thesis. Finally, Chapter \ref{chapter:future-work} gives an outlook for planned and possible extensions in the future.

\section{Motivation}\label{section:introduction:motivation}

The motivation behind this thesis is the creation of a micro-frontend prototype that should replace the old monolithic application within the company sometime in the future. Someday prototype should be more or less equal to the old application in terms of functionality. The first step is to break down the existing monolithic frontend into micro-frontends. The existing functionality must be reimplemented using a state-of-the-art approach. The micro-frontend architecture involves decomposing an application into smaller, loosely coupled services, which are easier to manage. The services are independently developable, deployable, and scalable. Having a single frontend application for multiple microservices circumvents the idea of independent development and deployment. The goal behind micro-frontends is to provide greater flexibility, agility and scalability. However, other hurdles have to be overcome, when this architectural style is implemented. The introduction of multiple different applications running on a single website introduces complexity in the form of inter-application communication, state management, and versioning. Another challenge is to have an integration mechanism that can orchestrate the micro-frontends at runtime. Another issue is over-fetching and over-requesting data. Each micro-frontend might request the same data from the backend, which leads to unnecessary network traffic and a higher load on the backend.

\bigskip

\noindent These problems should be explored and solved during the implementation of the prototype. The problem of over-fetching and over-requesting should be handled using GraphQL. GraphQL can improve performance and reduce network traffic by allowing the client to specify the necessary fields of the data. Combined with a micro-frontend architecture, GraphQL could significantly improve the user experience. Many GraphQL clients provide some form of caching GraphQL query results. By default, every micro-frontend would have its own cache instance. However, the prototype should explore whether a single caching layer for all applications can bring improvements by avoiding multiple requests to fetch a resource already in the cache. Another approach to improve performance that should be explored is by removing fields from a GraphQL query already stored in the cache. It is to be investigated whether loading only parts of the data improves network traffic in the form of request size and response size. These potential improvements should be investigated to determine if they have an advantage over the na√Øve approach. The evaluation should also discuss whether the potential improvement is worth the additional complexity due to the shared cache layer and query reduction mechanism.

\section{Hypothesis}\label{section:introduction:hypothesis}

The first hypothesis focuses on the performance improvement that GraphQL can bring to micro-frontend architectures.

\paragraph{Hypothesis 1} 
A micro-frontend architecture using a shared GraphQL caching layer with query reduction can solve the problems of over-fetching and over-requesting inside a distributed architecture. The total number of network requests and network traffic can be drastically reduced.

\bigskip

\noindent The second hypothesis suggests that the caching strategy proposed in the thesis is adaptable and flexible enough to be applied successfully in various contexts, regardless of the specific technologies used. The strategy is not limited to a technology stack and can be applied to various systems with different architectures. The thesis focuses on the caching strategy rather than the technologies used, indicating that the proposed approach can be implemented across different technologies and systems.

\paragraph{Hypothesis 2}
The caching strategy proposed in this thesis is versatile enough to be effectively implemented in various contexts, providing sufficient flexibility to be independent of the technology used.

\bigskip

\noindent The work results should prove that GraphQL can solve the performance problems of a micro-frontend architecture. The proof is provided by designing and implementing a micro-frontend architecture, writing a shared caching layer, and implementing a mechanism to remove fields from a query that are already stored in the cache.
