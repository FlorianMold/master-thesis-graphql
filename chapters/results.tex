\chapter{Results}\label{chapter:results}

This chapter measures whether a micro-frontend architecture with GraphQL and a shared caching layer can provide a performance improvement over a separated cache. In total, the micro-frontend architecture implements four \acp{SPA} and nine widgets. The major part of the implementation was done using Angular, but one single widget was implemented in React. This was done to showcase whether the shared caching layer could be used with every technology. Furthermore, a \ac{BFF} service was developed in GraphQL that is tailored to the needs of the micro-frontends. The \ac{BFF} service is used to aggregate the data from the microservices and to provide it to the micro-frontends. An overview of the prototypical architectures communicates with the GraphQL \ac{API} is shown in listing \ref{fig:results:micro-frontend-prototype}.

\ifshowImages
\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{images/results/micro-frontend-prototype.png}
  \caption{Architecture of the micro-frontend prototype.}\label{fig:results:micro-frontend-prototype}
\end{figure}
\fi

\section{Performance measurement}

This section explains how the micro-frontend architecture was evaluated in terms of the hypothesis. Three distinct approaches were identified to measure the performance of the shared GraphQL caching layer. The architecture allows switching easily between these three approaches.

\begin{enumerate}
  \item \textbf{Separate Cache and no reduced queries}: All remote modules use a separate cache and no queries are reduced with the help of the cache.
  \item \textbf{Shared Cache and no reduced queries}: The remote modules share the same cache instance and no queries are reduced with the help of the cache.
  \item \textbf{Shared Cache and reduced queries}: ALL remote modules share the same instance of the cache and queries are reduced by utilizing the cache.
\end{enumerate}

\noindent To measure and compare the performance of these three approaches, two exemplary paths through the application were planned. These paths were intended to show how many network requests were made to the GraphQL \ac{API} and how much network traffic was generated in the process. To make the measurement as close as possible to a real application, a large amount of mock data was generated for the GraphQL \ac{API}. With this large amount of data, it is easier to measure the differences in response size. Smaller datasets only make a big difference, if the application is used for longer periods. The next section details the results of the first path through the application.

\subsection{Evaluation}

This section describes how the shared caching layer and the reduction of queries were tested for the prototypical micro-frontend architecture. It explains the user journey through the application and shows the results for the three different approaches. The figure \ref{fig:results:evaluation-path} shows the steps through the micro-frontend architecture that were used to measure the possible performance improvements of the shared caching layer and the reduction of queries.

\ifshowImages
\begin{figure}[H]
\centering
\includegraphics[width=1\linewidth]{images/results/evaluation-path.png}
\caption{The user journey through the application to measure the performance of the micro-frontend architecture.}\label{fig:results:evaluation-path}
\end{figure}
\fi

\noindent Without the use of a caching system, the GraphQL \ac{API} would have to execute 59 queries to provide the data for the path through the application. How the prototypical micro-frontend architecture can be configured to use one of the three approaches is already explained in section \ref{section:applied-methods:shared-caching-layer} and section \ref{subsection:applied-methods:query-reduction:testing-query-reduction}. 

The 59 GraphQL queries executed by the user journey is shown in figure \ref{fig:results:graphql-queries}

\ifshowImages
\begin{figure}[H]
\centering
\includegraphics[width=1\linewidth]{images/results/graphql-queries.png}
\caption{All GraphQL queries.}\label{fig:results:graphql-queries}
\end{figure}
\fi

\subsubsection{Separate cache, no query reduction}

In this approach, each micro frontend has its instance of the GraphQL client and \texttt{InMemoryCache}. The queries are not reduced using the cache. After completing the journey through the application, the following metrics were collected.

\begin{itemize}
  \item 47 GraphQL requests
  \item 10.7MB transferred
\end{itemize}

To configure this behavior the following settings have to be provided to the \texttt{GRAPHQL\_CLIENT\_OPTIONS\_CONFIG}- and \texttt{REDUCE\_QUERY\_OPTIONS} injection tokens of the micro-frontends.

\begin{itemize}
  \item \texttt{shareCache: false}
  \item \texttt{reduceQueries: false}
\end{itemize}

\noindent 47 requests have to be made to the GraphQL backend which can be seen in figure \ref{fig:results:no-shared-cache-no-reduction}. 6 of the 53 requests are not executed, because these requests are done to load the other micro-frontends from their remote location. These requests are only needed for the functionality of the micro-service architecture.

\ifshowImages
\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{images/results/1-attempt/no-shared-cache-no-reduction.png}
\caption{All requests made during the measurement of the first approach}\label{fig:results:no-shared-cache-no-reduction}
\end{figure}
\fi

\noindent The total size of the requests was 17.46 KB and the size of the responses was 10.78 MB. The 47 queries retrieve a total of 61426 records from the GraphQL backend.

\subsubsection{Shared cache, no query reduction}

In this approach, the cache is shared by all micro-frontends, and queries are not reduced by data already present in the cache. After completing the journey through the application, the following metrics were collected.

\begin{itemize}
  \item 36 GraphQL requests
  \item 8.5 MB transferred
\end{itemize}

\noindent To configure this behavior the following settings have to be provided to the \texttt{GRAPHQL\_CLIENT\_OPTIONS\_CONFIG} and \texttt{REDUCE\_QUERY\_OPTIONS} injection tokens of the micro-frontends.

\begin{itemize}
  \item \texttt{shareCache: true}
  \item \texttt{reduceQueries: false}
\end{itemize}

\noindent 36 requests have to be made to the GraphQL backend which can be seen in figure \ref{fig:results:no-shared-cache-no-reduction}. 6 requests have to be subtracted (settings.json, module-federation.manifest.json) like previously.

\ifshowImages
\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{images/results/1-attempt/shared-not-reduced-cache.png}
\caption{All requests made during the measurement of the second approach}\label{fig:results:shared-cache-no-reduction}
\end{figure}
\fi

\noindent The total size of the queries was 15.176 KB and the size of the responses was 8.5 MB. The 36 queries retrieve a total of 51319 records from the GraphQL backend.

\subsubsection{Shared cache, query reduction}

With this approach, the cache is shared between all the micro-frontends, and the queries are reduced with already existing data inside the cache. After completing the journey through the application, the following metrics were collected.

\begin{itemize}
  \item 36 GraphQL requests
  \item 8.4 MB transferred
\end{itemize}

\noindent To configure this behavior the following settings have to be provided to the \texttt{GRAPHQL\_CLIENT\_OPTIONS\_CONFIG} and \texttt{REDUCE\_QUERY\_OPTIONS} injection tokens of the micro-frontends.

\begin{itemize}
  \item \texttt{shareCache: true}
  \item \texttt{reduceQueries: false}
\end{itemize}

\noindent 36 requests have to be made to the GraphQL backend which can be seen in figure \ref{fig:results:no-shared-cache-no-reduction}. 6 requests have to be subtracted (settings.json, module-federation.manifest.json).

\ifshowImages
\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{images/results/1-attempt/no-shared-cache-no-reduction.png}
\caption{All requests made during the measurement of the third approach.}\label{fig:results:shared-cache-reduction}
\end{figure}
\fi

\noindent The total size of the queries was 13.533 KB and the size of the responses was 8.37 MB. The 36 queries retrieve a total of 51319 records from the GraphQL backend.

\subsubsection{Comparison between the three approaches}

This section compares the different approaches in terms of request- and response-sizes.

\paragraph{Comparing the first- and second-approach}

When comparing the first- with the second approach there is a massive difference in the number of network requests made to the GraphQL backend and the size of the requests and responses, as seen in table \ref{table:results:size-comparison-first-path-no-cache-no-reduction-cache-no-reduction}. The shared cache approach requires 11 fewer network requests than the separate cache approach. Since the queries are not reduced in this comparison, the additional network queries account for the overall difference in request- and response size. The 11 additional requests from the first approach send an additional 2.29 KB to the backend and return about an additional 2.34 MB from the backend. Therefore, 22\% of the total response size can be saved by using only one shared cache. Another interesting observation is that the shared cache approach retrieves 10107 fewer records than the naive approach, which is 16\% of the total records returned.

\ifshowTables
\begin{table}[H]
    \begin{tabular}{|l|l|l|l|l|}
    \hline
      & Request Size (B) & Response Size (B) & Requests & Records \\
    \hline
     No Reduction, Separate Cache & 17462 & 10780656 & 47 & 61426 \\
     \hline
     No Reduction, Shared Cache & 15176 & 8437211 & 36 & 51319 \\
     \hline
     \hline
     \textbf{Diff} & \textbf{2286} & \textbf{2343445} & \textbf{11} & \textbf{10107} \\
     \hline
     \textbf{Reduction \%} & \textbf{13\%} & \textbf{22\%} & \textbf{23\%} & \textbf{16\%} \\
     \hline
    \end{tabular}
    \caption{Comparing the requests and responses of the first- and second-approach.}
    \label{table:results:size-comparison-first-path-no-cache-no-reduction-cache-no-reduction}
\end{table}
\fi

\noindent Following requests have been omitted when using a shared cache between the micro-frontends:

\begin{itemize}\item allCountries(User-MF, Contact-MF): 2
  \item allSalutations(User-MF, Contact-MF): 2
  \item allTitles(User-MF, Contact-MF): 2
  \item allArticleUnits(Sales-MF): 1
  \item allCurrencies(Sales-MF): 1
  \item allVats(Sales-MF): 1
  \item allSalesCountries(Sales-MF): 1
  \item allInvoiceTypes(Sales-MF): 1
\end{itemize}

\noindent The data of the requests is usually used for filling select controls inside detail views and has to be fetched in every micro-frontends, when not using a shared cache. The first three queries are used inside micro-frontends on the dashboard, the contact micro-frontend, and the user micro-frontend. The last five queries are used inside micro-frontends on the dashboard and the sales micro-frontend.

\paragraph{Comparing the first- and third-approach}

Like in the previous comparison, there is also a massive difference in the number of network requests made to the GraphQL backend and the size of the requests and responses, as seen in table \ref{table:results:size-comparison-first-path-no-cache-no-reduction-cache-reduction}. Just like before, there is a difference in the 11 GraphQL queries that are sent to the backend. However, due to the reduction in queries, the difference in the size of the queries and responses is greater than before. All queries of the first approach send 3.92 KB more and return about 2.41 MB more from the backend compared to the third approach. A shared cache and query reduction can save about 22\% response sizes. As before, 16\% fewer records need to be fetched from the backend.

\ifshowTables
\begin{table}[H]
    \begin{tabular}{|l|l|l|l|l|}
    \hline
       & Request Size (B) & Response Size (B) & Requests & Records  \\
    \hline
     No Reduction, Separate Cache & 17462 & 10780656 & 47 & 61426 \\
     \hline
     Reduction, Shared Cache & 13533 & 8374763 & 36 & 51319 \\
     \hline
     \hline
     \textbf{Diff} & \textbf{3929} & \textbf{2405893} & \textbf{11} & \textbf{10107} \\
     \hline
    \textbf{Reduction \%} & \textbf{23\%} & \textbf{22\%} & \textbf{23\%} & \textbf{16\%} \\
     \hline
    \end{tabular}
    \caption{Comparing the requests and responses of the first- and third-approach.}
    \label{table:results:size-comparison-first-path-no-cache-no-reduction-cache-reduction}
\end{table}
\fi

\paragraph{Comparing the second- and third-approach}

Between the first- and the second approach, there is almost no difference in request- and response size compared to the other comparisons, as seen in table \ref{table:results:size-comparison-first-path-no-cache-no-reduction-cache-reduction}. As seen earlier, both approaches have the same number of queries since the cache is shared by all micro-frontends. Thus, the only difference in request and response size between the two approaches comes from the use of query reduction. By using the third approach, the size of the total requests is reduced by 1.64 KB (11\%). The difference between the response sizes (62.45 KB) is almost zero compared to the amount of data returned.

\ifshowTables
\begin{table}[H]
    \begin{tabular}{|l|l|l|l|l|}
    \hline
      & Request Size (B) & Response Size (B) & Requests & Records \\
    \hline
     No Reduction, Shared Cache & 15176 &  8437211 & 36 & 51319 \\
     \hline
     Reduction, Shared Cache &  13533 &  8374763 & 36 & 51319 \\
     \hline
     \hline
     \textbf{Diff} & \textbf{1643} & \textbf{62448} & \textbf{0} & \textbf{0} \\
     \hline
     \textbf{Reduction \%} & \textbf{11\%} & \textbf{0\%} & \textbf{-} & \textbf{-} \\
     \hline
    \end{tabular}
    \caption{Comparing the requests and responses of the second- and third-approach.}
    \label{table:results:size-comparison-first-path-cache-no-reduction-cache-reduction}
\end{table}
\fi


\input{chapters/results/comparison-reduced-non-reduced-queries.tex}
