\chapter{Conclusion}\label{chapter:conclusion}

\noindent For the validation of the first hypothesis, which states that using GraphQL with a common caching layer and a mechanism to reduce queries can prevent over-fetching and over-requesting, a micro-frontend architecture with four \acp{SPA} and eight widgets were designed and implemented. Before the implementation started, the old legacy system was analyzed to identify potential bounded contexts that could be extracted into a micro-frontend. The prototype was implemented using mainly Angular and for one widget React. The integration of the micro-frontends was done with client-side integration by using Webpack's Module Federation. A \ac{BFF} service in the form of a GraphQL \ac{API} was implemented using Apollo Server. This service provides an abstraction layer for the interfaces of the micro-services that run inside the cluster. The \ac{BFF} takes care of aggregating data from multiple microservice and offering them as a single query for example. During development, the GraphQL \ac{API} was querying and mutating mocked datasets. The micro-frontend prototype will be integrated into the company's infrastructure sometime in the future. Therefore, the existing GraphQL queries will be used later in production, so the results of the evaluations are very expressive.

\bigskip

\noindent The first step was implementing a communication system, where the application could communicate with the remote modules. With the help of the communication pattern, the shared caching layer was implemented. To further improve the performance by providing the applications with the possibility to remove fields from GraphQL queries that are already stored inside the cache. This behavior is not natively implemented in Apollo Client, but \href{https://github.com/appmotion/apollo-augmented-hooks}{apollo-augmented-hooks} library provided exactly that functionality. But the library was outdated and lacked support for other frameworks than React. Therefore, the library was forked and the functionality was made technology agnostic. Some new features were added to further utilize the cache to reduce unnecessary fields from a query.

\bigskip

\noindent To compare, whether the shared caching layer and the reduction of queries bring a performance improvement, three distinct approaches were identified to compare them. The first approach was a naive approach with no shared caching layer and no reduction of queries. The second approach was using the shared caching layer and no reduction of queries. And the third approach used the shared caching layer and the reduction of queries. Measuring and comparing the results of the measurements came with surprising results. The shared caching layer brought immense performance gains because it significantly reduced the number of network requests and reduced the total response size by multiple megabytes. But the reduction of queries with the help of the functionality of the library has not brought the expected results. In contrast to the savings from the shared caching layer, the reduction of queries does not make a significant difference, when comparing the request sizes and response sizes. The additional functionality to reduce queries with the help of the cache brings additional complexity in the form of maintaining the library. Each new release of the \texttt{InMemoryCache} of Apollo could break the implementation, as the library depends on the functionality of the cache directly. Changing the public \ac{API} might break the workflow of reducing queries. Another difficulty that comes with using the query reduction mechanism is stale data. By fetching only fields that are not already in the cache, the data in the cache might become invalid. Especially for data that is rapidly changed, outdated data and fresh data might be mixed in the same cache object. The Apollo Client provides fetch policies to handle data that is rapidly changing, but this makes the use of query reduction unnecessary. Based on the built prototype and its use cases it does not make sense to use query reduction. The prototype mostly consists of a list view and a detail view for data from the GraphQL \ac{API}. This scenario does not leverage the potential of query reduction, because not many fields are emitted from the query. After all, the list view only shows a handful of fields, that can be omitted later.

\bigskip

\noindent A use-case for the query reduction might be an e-commerce application.

\bigskip

\noindent Based upon the discussion points, hypothesis I is partially confirmed. The number of requests and network traffic can be drastically reduced with the help of a shared caching layer. Using this approach is a simple and relatively implemented solution that brings enormous performance improvements. But using a mechanism to reduce queries with existing fields in the cache, does not bring the desired performance improvements in the contexts of this prototype. The theoretical example above shows where query reduction circumvents the limitations of the Apollo Client and brings massive performance improvements.

\bigskip

\noindent To validate the second hypothesis, which states that the prototype should provide enough freedom in the choice of technology, a micro frontend was written using React and embedded in the shell application. Module Federation is a great tool and provides lots of options for integrating applications from various frameworks into the application shell. The application shell has implemented abstractions for integrating other frameworks than Angular into the unidirectional data flow. The React application was able to integrate with the existing architecture and use both the shared caching layer and the query reduction mechanism. The architecture is thus theoretically open to the free choice of technology. But it has to be considered that running multiple frontend frameworks on the same architecture leads to large bundle sizes, which negatively impact the performance of the client.
